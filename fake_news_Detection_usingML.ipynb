{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yRb39JJGzNWG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import string\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "true = pd.read_csv('/content/true.csv')\n",
        "fake = pd.read_csv('/content/fake.csv')\n",
        "\n",
        "true['Class'] = \"true\"\n",
        "fake['Class'] = \"fake\"\n",
        "\n",
        "data = pd.concat([true, fake], ignore_index=True)\n",
        "\n",
        "print(data.head())\n",
        "print(data.isnull().sum())\n",
        "\n",
        "df = data.dropna()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t15RoR52Kfmg",
        "outputId": "a456c609-4479-49a1-df05-9a8482973cf8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0  As U.S. budget fight looms, Republicans flip t...   \n",
            "1  U.S. military to accept transgender recruits o...   \n",
            "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
            "3  FBI Russia probe helped by Australian diplomat...   \n",
            "4  Trump wants Postal Service to charge 'much mor...   \n",
            "\n",
            "                                                text       subject  \\\n",
            "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
            "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
            "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
            "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
            "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
            "\n",
            "                 date Class  \n",
            "0  December 31, 2017   true  \n",
            "1  December 29, 2017   true  \n",
            "2  December 31, 2017   true  \n",
            "3  December 30, 2017   true  \n",
            "4  December 29, 2017   true  \n",
            "title      0\n",
            "text       0\n",
            "subject    0\n",
            "date       0\n",
            "Class      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['processed_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "X = df['processed_text']\n",
        "y = df['Class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n"
      ],
      "metadata": {
        "id": "EinEO1qPKmGE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "sample_article = [\" Eventually you run out of other people’s money,” he said. Meadows was among Republicans who voted in late December for their party’s debt-financed tax overhaul, which is expected to balloon the federal budget deficit and add about $1.5 trillion over 10 years to the $20 trillion national debt. “It’s interesting to hear Mark talk about fiscal responsibility,” Democratic U.S.\"]\n",
        "sample_article_vec = vectorizer.transform(sample_article)\n",
        "prediction = model.predict(sample_article_vec)\n",
        "print(f\"Prediction (true: 0, fake: 1): {prediction[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yElkxF-hKqFm",
        "outputId": "549e23c7-1433-4de5-9ff7-aaebd065b405"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.33%\n",
            "Confusion Matrix:\n",
            "[[4361  289]\n",
            " [ 310 4020]]\n",
            "Prediction (true: 0, fake: 1): fake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U3EsibKxzQdI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}